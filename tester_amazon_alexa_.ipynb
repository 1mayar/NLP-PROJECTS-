{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install nltk==3.8.1 scikit-learn==1.4.2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VJ5RLxteLuZc",
        "outputId": "ee6c33de-2b63-44fb-a173-1f3700af3b19"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk==3.8.1 in /usr/local/lib/python3.10/dist-packages (3.8.1)\n",
            "Collecting scikit-learn==1.4.2\n",
            "  Downloading scikit_learn-1.4.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk==3.8.1) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk==3.8.1) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk==3.8.1) (2024.5.15)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk==3.8.1) (4.66.5)\n",
            "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.10/dist-packages (from scikit-learn==1.4.2) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn==1.4.2) (1.13.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn==1.4.2) (3.5.0)\n",
            "Downloading scikit_learn-1.4.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.1/12.1 MB\u001b[0m \u001b[31m44.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: scikit-learn\n",
            "  Attempting uninstall: scikit-learn\n",
            "    Found existing installation: scikit-learn 1.3.2\n",
            "    Uninstalling scikit-learn-1.3.2:\n",
            "      Successfully uninstalled scikit-learn-1.3.2\n",
            "Successfully installed scikit-learn-1.4.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from imblearn.pipeline import Pipeline as ImbPipeline\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "import nltk\n",
        "import re\n",
        "# Download required NLTK data\n",
        "nltk.download('punkt', quiet=True)\n",
        "nltk.download('stopwords', quiet=True)\n",
        "nltk.download('wordnet', quiet=True)\n",
        "\n",
        "# Load the data\n",
        "data = pd.read_csv('amazon_alexa.tsv', sep='\\t')\n",
        "\n",
        "# Preprocess the text data\n",
        "stop_words = set(stopwords.words('english'))\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "def preprocess_text(text):\n",
        "    text = str(text).lower()\n",
        "    text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
        "    tokens = word_tokenize(text)\n",
        "    tokens = [lemmatizer.lemmatize(token) for token in tokens if token not in stop_words]\n",
        "    return ' '.join(tokens)\n",
        "\n",
        "data['processed_reviews'] = data['verified_reviews'].apply(preprocess_text)\n",
        "\n",
        "# Prepare the features and target\n",
        "X = data[['processed_reviews', 'variation']]\n",
        "y = data['feedback']\n",
        "\n",
        "# Split the data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Create the feature extraction pipeline\n",
        "feature_extraction = ColumnTransformer([\n",
        "    ('count', CountVectorizer(max_features=2000), 'processed_reviews'),\n",
        "    ('onehot', OneHotEncoder(handle_unknown='ignore'), ['variation']),\n",
        "], remainder='passthrough')\n",
        "\n",
        "# Create pipelines for different models with SMOTE\n",
        "pipelines = {\n",
        "    'Naive Bayes': ImbPipeline([\n",
        "        ('features', feature_extraction),\n",
        "        ('smote', SMOTE(random_state=42)),\n",
        "        ('clf', MultinomialNB())\n",
        "    ]),\n",
        "    'Logistic Regression': ImbPipeline([\n",
        "        ('features', feature_extraction),\n",
        "        ('smote', SMOTE(random_state=42)),\n",
        "        ('clf', LogisticRegression(random_state=42))\n",
        "    ]),\n",
        "    'SVM': ImbPipeline([\n",
        "        ('features', feature_extraction),\n",
        "        ('smote', SMOTE(random_state=42)),\n",
        "        ('clf', SVC(kernel='linear', random_state=42))\n",
        "    ]),\n",
        "    'Random Forest': ImbPipeline([\n",
        "        ('features', feature_extraction),\n",
        "        ('smote', SMOTE(random_state=42)),\n",
        "        ('clf', RandomForestClassifier(max_features=8, criterion = 'entropy', n_estimators=200, random_state=42))\n",
        "    ]),\n",
        "    'XGBoost': ImbPipeline([\n",
        "        ('features', feature_extraction),\n",
        "        ('smote', SMOTE(random_state=42)),\n",
        "        ('clf', XGBClassifier(max_depth=3, n_estimators=100, random_state=42))\n",
        "    ])\n",
        "}\n",
        "\n",
        "# Train and evaluate models\n",
        "results = {}\n",
        "for name, pipeline in pipelines.items():\n",
        "    pipeline.fit(X_train, y_train)\n",
        "    y_pred = pipeline.predict(X_test)\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    results[name] = accuracy\n",
        "    print(f\"{name} Accuracy: {accuracy:.4f}\")\n",
        "    print(classification_report(y_test, y_pred))\n",
        "    print()\n",
        "\n",
        "# Select the best model\n",
        "best_model = max(results, key=results.get)\n",
        "print(f\"Best model: {best_model} with accuracy: {results[best_model]:.4f}\")\n",
        "\n",
        "\n",
        "# Save the best model\n",
        "import joblib\n",
        "joblib.dump(pipelines[best_model], 'best_sentiment_model_with_variations.joblib')\n",
        "\n",
        "# Inference function\n",
        "def predict_sentiment(text, variation, rating, model):\n",
        "    processed_text = preprocess_text(text)\n",
        "    df = pd.DataFrame({\n",
        "        'processed_reviews': [processed_text],\n",
        "        'variation': [variation],\n",
        "        'rating': [rating]\n",
        "    })\n",
        "    sentiment = model.predict(df)[0]\n",
        "    return 'Positive' if sentiment == 1 else 'Negative'\n",
        "\n",
        "# Load the best model\n",
        "print(\"\\nLoading the best model...\")\n",
        "best_model = joblib.load('best_sentiment_model_with_variations.joblib')\n",
        "# Evaluation on new data\n",
        "new_texts = [\n",
        "    \"Exceptional items\",\n",
        "    \"Incredible merchandise\",\n",
        "    \"Top-notch offerings\",\n",
        "    \"Subpar item\",\n",
        "    \"Poorly made item\",\n",
        "    \"Low-quality goods.\"\n",
        "]\n",
        "variations = [\"Black  Dot\", \"White  Dot\", \"Black  Dot\", \"White  Dot\", \"Black  Dot\", \"White  Dot\"]\n",
        "ratings = [5, 5, 5, 2, 1, 1]\n",
        "true_labels = [1, 1, 1, 0, 0, 0]\n",
        "\n",
        "data = {\n",
        "    'text': new_texts,\n",
        "    'variation': variations,\n",
        "    'rating': ratings,\n",
        "    'true_label': true_labels\n",
        "}\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "print(\"\\nMaking predictions on new data...\")\n",
        "# Make predictions\n",
        "df['predicted_sentiment'] = df.apply(lambda row: predict_sentiment(row['text'], row['variation'], row['rating'], best_model), axis=1)\n",
        "df['predicted_label'] = df['predicted_sentiment'].map({'Positive': 1, 'Negative': 0})\n",
        "\n",
        "# Print results\n",
        "print(\"\\nResults:\")\n",
        "print(df)\n",
        "print(\"\\nAccuracy:\", accuracy_score(df['true_label'], df['predicted_label']))\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(df['true_label'], df['predicted_label'], target_names=['Negative', 'Positive']))\n",
        "\n",
        "# Print misclassified samples, if any\n",
        "misclassified = df[df['true_label'] != df['predicted_label']]\n",
        "if not misclassified.empty:\n",
        "    print(\"\\nMisclassified samples:\")\n",
        "    print(misclassified[['text', 'variation', 'rating', 'true_label', 'predicted_sentiment']])\n",
        "else:\n",
        "    print(\"\\nAll samples were correctly classified!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aeyV_2_fNIgB",
        "outputId": "2e4d2897-d8d8-4048-8138-2f8d4a6ee6e9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Naive Bayes Accuracy: 0.8810\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.39      0.50      0.44        58\n",
            "           1       0.95      0.92      0.93       572\n",
            "\n",
            "    accuracy                           0.88       630\n",
            "   macro avg       0.67      0.71      0.68       630\n",
            "weighted avg       0.90      0.88      0.89       630\n",
            "\n",
            "\n",
            "Logistic Regression Accuracy: 0.8905\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.44      0.74      0.55        58\n",
            "           1       0.97      0.91      0.94       572\n",
            "\n",
            "    accuracy                           0.89       630\n",
            "   macro avg       0.71      0.82      0.75       630\n",
            "weighted avg       0.92      0.89      0.90       630\n",
            "\n",
            "\n",
            "SVM Accuracy: 0.8889\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.43      0.69      0.53        58\n",
            "           1       0.97      0.91      0.94       572\n",
            "\n",
            "    accuracy                           0.89       630\n",
            "   macro avg       0.70      0.80      0.74       630\n",
            "weighted avg       0.92      0.89      0.90       630\n",
            "\n",
            "\n",
            "Random Forest Accuracy: 0.9302\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.72      0.40      0.51        58\n",
            "           1       0.94      0.98      0.96       572\n",
            "\n",
            "    accuracy                           0.93       630\n",
            "   macro avg       0.83      0.69      0.74       630\n",
            "weighted avg       0.92      0.93      0.92       630\n",
            "\n",
            "\n",
            "XGBoost Accuracy: 0.9222\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.68      0.29      0.41        58\n",
            "           1       0.93      0.99      0.96       572\n",
            "\n",
            "    accuracy                           0.92       630\n",
            "   macro avg       0.81      0.64      0.68       630\n",
            "weighted avg       0.91      0.92      0.91       630\n",
            "\n",
            "\n",
            "Best model: Random Forest with accuracy: 0.9302\n",
            "\n",
            "Loading the best model...\n",
            "\n",
            "Making predictions on new data...\n",
            "\n",
            "Results:\n",
            "                     text   variation  rating  true_label predicted_sentiment  \\\n",
            "0       Exceptional items  Black  Dot       5           1            Positive   \n",
            "1  Incredible merchandise  White  Dot       5           1            Negative   \n",
            "2     Top-notch offerings  Black  Dot       5           1            Positive   \n",
            "3             Subpar item  White  Dot       2           0            Negative   \n",
            "4        Poorly made item  Black  Dot       1           0            Positive   \n",
            "5      Low-quality goods.  White  Dot       1           0            Negative   \n",
            "\n",
            "   predicted_label  \n",
            "0                1  \n",
            "1                0  \n",
            "2                1  \n",
            "3                0  \n",
            "4                1  \n",
            "5                0  \n",
            "\n",
            "Accuracy: 0.6666666666666666\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    Negative       0.67      0.67      0.67         3\n",
            "    Positive       0.67      0.67      0.67         3\n",
            "\n",
            "    accuracy                           0.67         6\n",
            "   macro avg       0.67      0.67      0.67         6\n",
            "weighted avg       0.67      0.67      0.67         6\n",
            "\n",
            "\n",
            "Misclassified samples:\n",
            "                     text   variation  rating  true_label predicted_sentiment\n",
            "1  Incredible merchandise  White  Dot       5           1            Negative\n",
            "4        Poorly made item  Black  Dot       1           0            Positive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from imblearn.pipeline import Pipeline as ImbPipeline\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "import nltk\n",
        "import re\n",
        "# Download required NLTK data\n",
        "nltk.download('punkt', quiet=True)\n",
        "nltk.download('stopwords', quiet=True)\n",
        "nltk.download('wordnet', quiet=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e7WmXBdwqkmM",
        "outputId": "21ffb937-7d6e-4ff3-e2ad-77c5408d4273"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the data\n",
        "data = pd.read_csv('amazon_alexa.tsv', sep='\\t')\n",
        "\n",
        "# Preprocess the text data\n",
        "stop_words = set(stopwords.words('english'))\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "def preprocess_text(text):\n",
        "    text = str(text).lower()\n",
        "    text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
        "    tokens = word_tokenize(text)\n",
        "    tokens = [lemmatizer.lemmatize(token) for token in tokens if token not in stop_words]\n",
        "    return ' '.join(tokens)\n",
        "\n",
        "data['processed_reviews'] = data['verified_reviews'].apply(preprocess_text)"
      ],
      "metadata": {
        "id": "kgk99gHSXl_h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare the features and target\n",
        "X = data[['processed_reviews', 'variation']]\n",
        "y = data['feedback']\n",
        "\n",
        "# Split the data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
      ],
      "metadata": {
        "id": "MYGxsp9VXDgU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the feature extraction pipeline\n",
        "feature_extraction = ColumnTransformer([\n",
        "    ('count', CountVectorizer(max_features=2000), 'processed_reviews'),\n",
        "    ('onehot', OneHotEncoder(handle_unknown='ignore'), ['variation']),\n",
        "], remainder='passthrough')\n"
      ],
      "metadata": {
        "id": "6TXRGIQXOrYG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create pipelines for different models with SMOTE\n",
        "pipelines = {\n",
        "    'Naive Bayes': ImbPipeline([\n",
        "        ('features', feature_extraction),\n",
        "        ('smote', SMOTE(random_state=42)),\n",
        "        ('clf', MultinomialNB())\n",
        "    ]),\n",
        "    'Logistic Regression': ImbPipeline([\n",
        "        ('features', feature_extraction),\n",
        "        ('smote', SMOTE(random_state=42)),\n",
        "        ('clf', LogisticRegression(random_state=42))\n",
        "    ]),\n",
        "    'SVM': ImbPipeline([\n",
        "        ('features', feature_extraction),\n",
        "        ('smote', SMOTE(random_state=42)),\n",
        "        ('clf', SVC(kernel='linear', random_state=42))\n",
        "    ]),\n",
        "    'Random Forest': ImbPipeline([\n",
        "        ('features', feature_extraction),\n",
        "        ('smote', SMOTE(random_state=42)),\n",
        "        ('clf', RandomForestClassifier(max_features=8, criterion = 'entropy', n_estimators=200, random_state=42))\n",
        "    ]),\n",
        "    'XGBoost': ImbPipeline([\n",
        "        ('features', feature_extraction),\n",
        "        ('smote', SMOTE(random_state=42)),\n",
        "        ('clf', XGBClassifier(max_depth=3, n_estimators=100, random_state=42))\n",
        "    ])\n",
        "}"
      ],
      "metadata": {
        "id": "0LvI9OeWX4lW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train and evaluate models\n",
        "results = {}\n",
        "for name, pipeline in pipelines.items():\n",
        "    pipeline.fit(X_train, y_train)\n",
        "    y_pred = pipeline.predict(X_test)\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    results[name] = accuracy\n",
        "    print(f\"{name} Accuracy: {accuracy:.4f}\")\n",
        "    print(classification_report(y_test, y_pred))\n",
        "    print()"
      ],
      "metadata": {
        "id": "kDm-3MnnYiYF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "365e5d76-d963-484e-f385-e47b8890bc3e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Naive Bayes Accuracy: 0.8810\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.39      0.50      0.44        58\n",
            "           1       0.95      0.92      0.93       572\n",
            "\n",
            "    accuracy                           0.88       630\n",
            "   macro avg       0.67      0.71      0.68       630\n",
            "weighted avg       0.90      0.88      0.89       630\n",
            "\n",
            "\n",
            "Logistic Regression Accuracy: 0.8905\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.44      0.74      0.55        58\n",
            "           1       0.97      0.91      0.94       572\n",
            "\n",
            "    accuracy                           0.89       630\n",
            "   macro avg       0.71      0.82      0.75       630\n",
            "weighted avg       0.92      0.89      0.90       630\n",
            "\n",
            "\n",
            "SVM Accuracy: 0.8889\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.43      0.69      0.53        58\n",
            "           1       0.97      0.91      0.94       572\n",
            "\n",
            "    accuracy                           0.89       630\n",
            "   macro avg       0.70      0.80      0.74       630\n",
            "weighted avg       0.92      0.89      0.90       630\n",
            "\n",
            "\n",
            "Random Forest Accuracy: 0.9302\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.72      0.40      0.51        58\n",
            "           1       0.94      0.98      0.96       572\n",
            "\n",
            "    accuracy                           0.93       630\n",
            "   macro avg       0.83      0.69      0.74       630\n",
            "weighted avg       0.92      0.93      0.92       630\n",
            "\n",
            "\n",
            "XGBoost Accuracy: 0.9222\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.68      0.29      0.41        58\n",
            "           1       0.93      0.99      0.96       572\n",
            "\n",
            "    accuracy                           0.92       630\n",
            "   macro avg       0.81      0.64      0.68       630\n",
            "weighted avg       0.91      0.92      0.91       630\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Select the best model\n",
        "best_model = max(results, key=results.get)\n",
        "print(f\"Best model: {best_model} with accuracy: {results[best_model]:.4f}\")\n",
        "\n",
        "\n",
        "# Save the best model\n",
        "import joblib\n",
        "joblib.dump(pipelines[best_model], 'best_sentiment_model_with_variations.joblib')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3A3FG365YsmX",
        "outputId": "4373f828-d9e4-40ca-8601-c70c62992d2f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best model: Random Forest with accuracy: 0.9302\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['best_sentiment_model_with_variations.joblib']"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Inference function\n",
        "def predict_sentiment(text, variation, rating, model):\n",
        "    processed_text = preprocess_text(text)\n",
        "    df = pd.DataFrame({\n",
        "        'processed_reviews': [processed_text],\n",
        "        'variation': [variation],\n",
        "        'rating': [rating]\n",
        "    })\n",
        "    sentiment = model.predict(df)[0]\n",
        "    return 'Positive' if sentiment == 1 else 'Negative'\n"
      ],
      "metadata": {
        "id": "eC_ccUWIYwxm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the best model\n",
        "print(\"\\nLoading the best model...\")\n",
        "best_model = joblib.load('best_sentiment_model_with_variations.joblib')\n",
        "# Evaluation on new data\n",
        "new_texts = [\n",
        "    \"Exceptional items\",\n",
        "    \"Incredible merchandise\",\n",
        "    \"Top-notch offerings\",\n",
        "    \"Subpar item\",\n",
        "    \"Poorly made item\",\n",
        "    \"Low-quality goods.\"\n",
        "]\n",
        "variations = [\"Black  Dot\", \"White  Dot\", \"Black  Dot\", \"White  Dot\", \"Black  Dot\", \"White  Dot\"]\n",
        "ratings = [5, 5, 5, 2, 1, 1]\n",
        "true_labels = [1, 1, 1, 0, 0, 0]\n",
        "\n",
        "data = {\n",
        "    'text': new_texts,\n",
        "    'variation': variations,\n",
        "    'rating': ratings,\n",
        "    'true_label': true_labels\n",
        "}\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "print(\"\\nMaking predictions on new data...\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oMCgT_RFY5TJ",
        "outputId": "4fc2a20e-9a60-48a7-bb24-5c1e7e77768a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Loading the best model...\n",
            "\n",
            "Making predictions on new data...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Make predictions\n",
        "df['predicted_sentiment'] = df.apply(lambda row: predict_sentiment(row['text'], row['variation'], row['rating'], best_model), axis=1)\n",
        "df['predicted_label'] = df['predicted_sentiment'].map({'Positive': 1, 'Negative': 0})\n",
        "\n",
        "# Print results\n",
        "print(\"\\nResults:\")\n",
        "print(df)\n",
        "print(\"\\nAccuracy:\", accuracy_score(df['true_label'], df['predicted_label']))\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(df['true_label'], df['predicted_label'], target_names=['Negative', 'Positive']))\n",
        "\n",
        "# Print misclassified samples, if any\n",
        "misclassified = df[df['true_label'] != df['predicted_label']]\n",
        "if not misclassified.empty:\n",
        "    print(\"\\nMisclassified samples:\")\n",
        "    print(misclassified[['text', 'variation', 'rating', 'true_label', 'predicted_sentiment']])\n",
        "else:\n",
        "    print(\"\\nAll samples were correctly classified!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FnTg6L-wapPw",
        "outputId": "e1599d9e-71a0-4f2e-fdae-65013aa915e5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Results:\n",
            "                     text   variation  rating  true_label predicted_sentiment  \\\n",
            "0       Exceptional items  Black  Dot       5           1            Positive   \n",
            "1  Incredible merchandise  White  Dot       5           1            Negative   \n",
            "2     Top-notch offerings  Black  Dot       5           1            Positive   \n",
            "3             Subpar item  White  Dot       2           0            Negative   \n",
            "4        Poorly made item  Black  Dot       1           0            Positive   \n",
            "5      Low-quality goods.  White  Dot       1           0            Negative   \n",
            "\n",
            "   predicted_label  \n",
            "0                1  \n",
            "1                0  \n",
            "2                1  \n",
            "3                0  \n",
            "4                1  \n",
            "5                0  \n",
            "\n",
            "Accuracy: 0.6666666666666666\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    Negative       0.67      0.67      0.67         3\n",
            "    Positive       0.67      0.67      0.67         3\n",
            "\n",
            "    accuracy                           0.67         6\n",
            "   macro avg       0.67      0.67      0.67         6\n",
            "weighted avg       0.67      0.67      0.67         6\n",
            "\n",
            "\n",
            "Misclassified samples:\n",
            "                     text   variation  rating  true_label predicted_sentiment\n",
            "1  Incredible merchandise  White  Dot       5           1            Negative\n",
            "4        Poorly made item  Black  Dot       1           0            Positive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LV_8Q4xPa98q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "EaAgBhwWFKKC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "z95noqvHFKV6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "oCc3tovqFKdB"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}